# [논문 초고] 7. 논의 (Discussion)

## 7.1. 의견 붕괴의 메커니즘: 사회적 증거와 정보적 연쇄

실험 결과에서 가장 주목할 점은 **C4(순수 통계) 조건의 강력한 수렴성**이다. 인간의 경우 구체적인 설득 논거 없이 숫자만 보았을 때 반발심(Reactance)을 가질 수 있으나, LLM 에이전트들은 지배적인 통계 수치를 ‘가장 확률적으로 올바른 정답’으로 처리하는 경향을 보였다. 이는 LLM의 학습 메커니즘 자체가 다수의 텍스트 데이터로부터 확률적 분포를 학습하는 특성에서 기인한 것으로 판단된다. 즉, 상호작용 환경에서의 통계 데이터는 에이전트에게 강력한 ‘베이지안 업데이트’의 단서로 작용한다.

## 7.2. 에코 체임버 현상과 AI 다양성

초기 50:50으로 설정된 시나리오임에도 불구하고, 우연히 첫 라운드에서 1-2명만 더 많은 쪽이 발생하면 그 미세한 차이가 다음 라운드에서 증폭되는 ‘정보적 연쇄(Informational Cascade)’가 발생한다. 이는 AI 시스템이 민주적 의사결정의 도구로 사용될 때 매우 위험한 요소가 될 수 있다. 초기 설정값이나 우연한 선입견이 집단 전체의 결론으로 고착화(Lock-in)될 수 있기 때문이다.

## 7.3. 연구의 한계점

1. **모델 편향성:** 본 연구는 Mistral-7B라는 단일 모델을 사용하여 진행되었으므로, GPT-4나 Claude와 같은 다른 아키텍처를 가진 모델에서는 동조의 강도가 다를 수 있다.
2. **시나리오의 특수성:** 트롤리 딜레마는 이미 학습 데이터에 공리주의적 해법이 많이 포함되어 있을 가능성이 높다. 보다 중립적이거나 새로운 윤리적 난제에서의 검증이 추가로 필요하다.
