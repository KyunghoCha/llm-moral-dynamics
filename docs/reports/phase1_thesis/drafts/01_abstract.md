# [논문 초고] 제목 및 초록

## 제목: LLM 다중 에이전트 환경에서의 윤리적 의사결정 수렴 현상 연구: 사회적 정보 공개 수준에 따른 집단적 동조와 다양성 붕괴 분석

---

## 초록 (Abstract)

본 연구는 대규모 언어 모델(LLM)을 기반으로 한 다중 에이전트 시스템(MAS)이 복잡한 윤리적 딜레마 상황에서 상호작용할 때 발생하는 의사결정의 수렴(Convergence) 및 ‘의견 붕괴(Opinion Collapse)’ 현상을 실험적으로 탐구한다. 특히, 에이전트 간에 공유되는 정보의 양과 질(논거, 입장, 통계적 분포 등)이 집단의 다양성 유지와 합의 속도에 미치는 영향을 고찰하기 위해 고전적인 트롤리 딜레마(Trolley Problem)를 실험 시나리오로 채택하였다.

본 실험에서는 Mistral-7B 모델을 기반으로 한 30개의 에이전트 집단을 대상으로 15라운드 동안의 토론 및 상호작용 과정을 시뮬레이션하였다. 실험 조건은 정보 노출 수준에 따라 독립형(C0), 완전 정보(C1), 입장 전용(C2), 익명 기반(C3), 통계 정보(C4)의 5가지로 구성되었으며, 총 115회의 독립된 실험 세트를 통해 3,450여 건의 개별 의사결정 데이터를 분석하였다.

분석 결과, 모든 상호작용 조건에서 초기 50:50으로 균형 잡혔던 의견 분포가 시간에 따라 급격히 특정 방향(주로 공리주의적 선택)으로 수렴하는 현상이 일관되게 관찰되었다. 특히, 구체적인 논거 없이 투표 현황 및 통계 정보만 제공된 C4 조건과 전체 정보를 제공한 C1 조건에서 가장 빠르고 강력한 의견 수렴이 발생하였다. 이는 LLM 에이전트들이 타인의 복잡한 논리적 설득보다는 ‘다수의 선택’이라는 사회적 증거(Social Proof)에 더 민감하게 반응할 수 있음을 시사한다.

또한, 집단 엔트로피(H)의 변화 곡선과 합의 도달 시간(Time-to-Collapse) 분석을 통해, 사회적 정보의 공유가 AI 집단의 사고 다양성을 저해하고 '에코 체임버(Echo Chamber)' 현상을 가속화할 수 있음을 통계적으로 입증하였다. 본 연구의 결과는 향후 다중 AI 에이전트 거버넌스 및 민주적 의사결정 알고리즘 설계에 있어 다양성 보호를 위한 중립적 중재 메커니즘의 필요성을 강조한다.

**주제어:** LLM 에이전트, 사회적 수렴, 의견 붕괴, 트롤리 딜레마, AI 합의 메커니즘, 집단 역학
